# PAPER SCOPE
24.12.23 ~ 24.12.27 - 인텔 AI SW 아카데미 팀 프로젝트

논문 제목을 입력하면 자동적으로 대분류, 자연과학인 경우 중분류까지 연관성이 가장 높은 카테고리로 추천해주는 프로그램 입니다.

기본적인 구조는 자연어를 전처리하여 LSTM레이어를 가진 모델을 학습시킨 뒤, 입력받는 제목이 어느 카테고리에 연관성이 높은지 순서대로 출력하는 프로그램입니다.

대분류 모델과 중분류 모델로 구성되어 있고, 중분류 모델은 자연과학 카테고리만 구현되어 있습니다.

----------------------------------------------------------------------------------------------------------------------

### konlpy를 사용하였기에, JAVA JDK21을 설치하고 환경변수 설정을 해야합니다. 

### 사용한 패키지
- Python3.10
- JAVA JDK21
- Python에 사용된 패키지는 requirements.txt에서 확인이 가능합니다.

--------------------------------------------------------------------------------------------------

## 목차
### 1. 프로젝트 기획 이유
### 2. 데이터 수집 및 전처리
### 3. 모델 학습
### 4. 어플리케이션 구현
### 5. 디렉토리 구조
### 6. 


## 1. 프로젝트 기획 이유
논문은 다양한 분야에서 


## 2. 데이터 수집 및 전처리


**한국학술지인용색인** 논문 제목 검색 서비스 사이트에서 데이터 수집
- 외부 링크: https://www.kci.go.kr/kciportal/po/search/poArtiSearList.kci
<img src="C:\Users\user\Desktop\2024-12-26 162236.png">


논문에 사용되는 언어는 한국어와 영어만 제목을 추출하여 모델 학습에 사용했습니다.


konlpydml Okt를 이용해 문장을 형태소로 자르고, 결측치와 불용어를 제거한 뒤 합쳐서 keras tokenizer를 이용해 토큰화를 시킨다.


### 데이터 수집 및 전처리
- job01_crawling_paper_title.py
- job02_crawling_paper_sub_title.py

### 토큰화 및 데이터 전처리
- job03_preprocessing.py
- job04_preprocessing_sub.py


## 3. 모델 학습

자연어를 추론해 분류하는 모델을 만들기 위해서 LSTM 레이어를 사용했다.
그중 LSTM(단방향) 이 아닌 Bidirectional LSTM(양방향) 을 이용해서 레이어 층을 쌓아 분류 정확도가 더 높아질 수 있도록 하였다.


| 항목                             | LSTM | Bidirectional LSTM               |
|----------------------------------|------------------------------------------------------|------------------------------------------------------------|
| **방향**                         | 단방향 LSTM (한 방향만 처리)                            | 양방향 LSTM (두 방향 모두 처리)                              |
| **출력**                         | 모든 시퀀스 출력 (각 타임스텝에 대한 출력)              | 기본적으로 마지막 타임스텝의 출력만 반환 (eturn_sequences=True로 설정하여 전체 시퀀스를 반환) |
| **정보 처리**                    | 이전 시점의 정보만 사용                               | 과거와 미래의 정보를 모두 사용                              |



<img src="C:\Users\user\Desktop\flow01.png">



| **수집한 데이터** | 67,978 | 100% | 정확도 | epochs = 6 |
| **학습용 데이터** | 61,180 | 90% | accuracy | 0.8998 |
| **검증용 데이터** | 6,798 | 10% | val_accuracy | 0.5791 |
|----------------|----------------------------------|-------------------------|-----------------------------|
| **테스트 데이터** |  | % | accuracy |  |


| **수집한 데이터** | 19,657 | 100% | 정확도 | epochs = 6 |
| **학습용 데이터** | 17,691 | 90% | accuracy | 0.9643 |
| **검증용 데이터** | 1,966 | 10% | val_accuracy | 0.6480 |
|----------------|----------------------------------|-------------------------|-----------------------------|
| **테스트 데이터** |  | % | accuracy |  |



### 모델 학습
- job05_model_learning.py
- job06_sub_model_learning.py

### 모델 검증
- job07_model_predict.py
- job08_sub_model_predict.py




## 4. 어플리케이션 구현


어플리케이션은 PyQt5를 이용해서 구현했습니다.









## 5. 디렉토리 구조
- crawling_data
  - 논문 제목을 모은 .csv 파일을 저장하는 디렉토리 입니다.

- format_files
  - 불용어.csv, 엔코더.pickle, 토큰.pickle이 저장되는 디렉토리입니다.
  - 불용어.csv(한국어, 영어)는 다운로드 받으셔야 합니다.

- models
  - 학습으로 생성된 모듈이 저장되는 디렉토리입니다.

- train_test_split
  - 학습용과 검증용으로 나눈 데이터를 저장하는 디렉토리입니다.

